{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4b348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\CIEDEV/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7063542 parameters, 7063542 gradients\n",
      "\n",
      "Adding autoShape... \n",
      "YOLOv5  2021-4-27 torch 1.8.1 CUDA:0 (GeForce RTX 2060 SUPER, 8192.0MB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from PIL import Image\n",
    "from utils.general import xyxy2xywh\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path_or_model='last.pt')  # custom model\n",
    "model.conf = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15ac7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy\n",
    "\n",
    "dirr = 'E:/images/left_view'    ############################### USER INPUT\n",
    "\n",
    "save_img_dir = r'C:\\Users\\CIEDEV\\Desktop\\Nabin\\saved'  #########################     USERINPUT\n",
    "\n",
    "files = glob.glob(dirr + '/**/*.tiff', recursive=True)[600:800]  #--> ####### batchzize \n",
    "img_name = [ os.path.basename(img) for img in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a53ab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "result = model(files)  # applying model to img\n",
    "detection = result.xyxy  # coordinates of 2/3 bottles each image \n",
    "i = 0 \n",
    "dw = 1920 # img width # default\n",
    "dh = 1200 # img height  #default\n",
    "final_coords = [] #coords for the middle image\n",
    "for det in detection:\n",
    "\n",
    "    coords = det[:,:4].cpu().numpy()\n",
    "    x,y = dw/2, dh/2\n",
    "    \n",
    "    if len(coords) == 1:     ## code to identify center image and append to the final coord\n",
    "         final_coords.append(coords)\n",
    "    elif len(detection) == 2:\n",
    "        c1 = coords[0]\n",
    "        c2 = coords[1]\n",
    "        c1_x,c1_y = (c1[0] + c1[2])/2, (c1[1] + c1[3])/2\n",
    "        c2_x,c2_y = (c2[0] + c2[2])/2, (c2[1] + c2[3])/2\n",
    "        dist1 =  abs(c1_x - x) + abs(c1_y - y)\n",
    "        dist2 =  abs(c2_x - x) + abs(c2_y - y)\n",
    "        if dist1 < dist2:\n",
    "            final_coords.append(c1)\n",
    "        else:\n",
    "            final_coords.append(c2)\n",
    "    elif len(coords) == 3:\n",
    "        c1 = coords[0]\n",
    "        c2 = coords[1]\n",
    "        c3 = coords[2]\n",
    "        c1_x,c1_y = (c1[0] + c1[2])/2, (c1[1] + c1[3])/2\n",
    "        c2_x,c2_y = (c2[0] + c2[2])/2, (c2[1] + c2[3])/2\n",
    "        c3_x,c3_y = (c3[0] + c3[2])/2, (c3[1] + c3[3])/2\n",
    "        dist1 =  abs(c1_x - x) + abs(c1_y - y)\n",
    "        dist2 =  abs(c2_x - x) + abs(c2_y - y)\n",
    "        dist3 =  abs(c3_x - x) + abs(c3_y - y)\n",
    "        if dist1 < dist2 and dist1 < dist3:\n",
    "            final_coords.append(c1)\n",
    "        elif dist2 < dist1 and dist2 < dist3 :\n",
    "            final_coords.append(c2)\n",
    "        else :\n",
    "            final_coords.append(c3)\n",
    "    \n",
    "\n",
    "for index, coord in enumerate(final_coords):  \n",
    "    img = left_files[index] \n",
    "    name_img = img_name[index]\n",
    "    \n",
    "    try:\n",
    "        crop_img = img[int(coord[1]-10):int(coord[3]+10), 0: dw]  ## += 5 offset to confirm the bottle is center bottle\n",
    "#         crop_img = img[int(coord[1]-5):int(coord[3]), int(coord[0]): int(coord[2])]\n",
    "          \n",
    "    except Exception:\n",
    "        pass\n",
    "    os.chdir(save_img_dir)  # Save image to directory mentioned\n",
    "    cv2.imwrite(name_img, crop_img)\n",
    "\n",
    "print(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d608ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
